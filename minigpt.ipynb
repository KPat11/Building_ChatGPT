{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Finding unique characters for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('homer.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset:  908201\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of The Iliad\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: The Iliad\n",
      "\n",
      "Author: Homer\n",
      "\n",
      "Translator: Samuel Butler\n",
      "\n",
      "Release date: June 1, 2000 [eBook #2199]\n",
      "                Most recently updated: August 16, 2022\n",
      "\n",
      "Language: English\n",
      "\n",
      "Credits: Jim TinsleyRevised by Richard Tonsing.\n",
      "\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK THE ILIAD ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      THE ILIAD OF HOMER\n",
      "\n",
      "      Rendered into English Prose for\n",
      "      the use of those who cannot\n",
      "      read the original\n",
      "\n",
      "\n",
      "      by Samuel Butler\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      "\n",
      " BOOK I.\n",
      " BOOK II.\n",
      " BOOK III.\n",
      " BOOK IV.\n",
      " BOOK V.\n",
      " BOOK VI.\n",
      " BOO\n"
     ]
    }
   ],
   "source": [
    "#Looking at first 1000 characters\n",
    "print(text[:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !#$%()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz—‘’“”•™﻿\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "# unique characters that occur in text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenization: Encoding and Decoding Strategy\n",
    "\n",
    "I will be mapping characters to numbers and create functions to encode and decode. I know their are other methods like Sentencepiece or a byte-pair tokenizer like tiktoken which openai uses but I elected to code out instead of using libraries for learning/practice purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 58, 65, 65, 68, 68, 68, 1, 59, 71, 62, 58, 67, 57]\n",
      "hellooo friend\n"
     ]
    }
   ],
   "source": [
    "# Mapping\n",
    "encode_map = { ch:i for i,ch in enumerate(chars) }\n",
    "decode_map = { i:ch for i, ch in enumerate(chars) }\n",
    "\n",
    "#encoder takes string and maps to list of integers\n",
    "encode = lambda e: [encode_map[c] for c in e]\n",
    "#decode takes list of integers and outputs a string\n",
    "decode = lambda d: ''.join([decode_map[u] for u in d])\n",
    "\n",
    "print(encode(\"hellooo friend\"))\n",
    "print(decode(encode(\"hellooo friend\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([908201]) torch.int64\n",
      "tensor([87, 45, 61,  ..., 27, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "# encoding entire dataset using pytorch\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1001]) #peek at first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split into Train/Test\n",
    "Splitting train/test, chunk definitions, and batching for multiple chunks at same time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([87, 45, 61,  ..., 56, 61, 58])\n",
      "tensor([72, 73, 67,  ...,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "#taking 90% of data for train, and rest for validation\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(train_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([87, 45, 61, 58,  1, 41, 71, 68, 63])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will be training random chunks rather than every line for computation reasons\n",
    "chunk_size = 8\n",
    "train_data[:chunk_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([87]) the target is: 45\n",
      "When input is tensor([87, 45]) the target is: 61\n",
      "When input is tensor([87, 45, 61]) the target is: 58\n",
      "When input is tensor([87, 45, 61, 58]) the target is: 1\n",
      "When input is tensor([87, 45, 61, 58,  1]) the target is: 41\n",
      "When input is tensor([87, 45, 61, 58,  1, 41]) the target is: 71\n",
      "When input is tensor([87, 45, 61, 58,  1, 41, 71]) the target is: 68\n",
      "When input is tensor([87, 45, 61, 58,  1, 41, 71, 68]) the target is: 63\n"
     ]
    }
   ],
   "source": [
    "# Setting up next likely value logic and sanity checking\n",
    "\n",
    "x = train_data[:chunk_size]\n",
    "y = train_data[1:chunk_size+1]\n",
    "for i in range(chunk_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f\"When input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[58, 11,  1, 33, 58, 56, 73, 68],\n",
      "        [68, 59,  0,  1,  1,  1,  1,  1],\n",
      "        [57,  1, 76, 62, 73, 61,  1, 72],\n",
      "        [58, 72, 69, 58, 71, 54, 73, 58]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[11,  1, 33, 58, 56, 73, 68, 71],\n",
      "        [59,  0,  1,  1,  1,  1,  1,  1],\n",
      "        [ 1, 76, 62, 73, 61,  1, 72, 74],\n",
      "        [72, 69, 58, 71, 54, 73, 58, 65]])\n",
      "----\n",
      "When input is [58] the target is: 11\n",
      "When input is [58, 11] the target is: 1\n",
      "When input is [58, 11, 1] the target is: 33\n",
      "When input is [58, 11, 1, 33] the target is: 58\n",
      "When input is [58, 11, 1, 33, 58] the target is: 56\n",
      "When input is [58, 11, 1, 33, 58, 56] the target is: 73\n",
      "When input is [58, 11, 1, 33, 58, 56, 73] the target is: 68\n",
      "When input is [58, 11, 1, 33, 58, 56, 73, 68] the target is: 71\n",
      "When input is [68] the target is: 59\n",
      "When input is [68, 59] the target is: 0\n",
      "When input is [68, 59, 0] the target is: 1\n",
      "When input is [68, 59, 0, 1] the target is: 1\n",
      "When input is [68, 59, 0, 1, 1] the target is: 1\n",
      "When input is [68, 59, 0, 1, 1, 1] the target is: 1\n",
      "When input is [68, 59, 0, 1, 1, 1, 1] the target is: 1\n",
      "When input is [68, 59, 0, 1, 1, 1, 1, 1] the target is: 1\n",
      "When input is [57] the target is: 1\n",
      "When input is [57, 1] the target is: 76\n",
      "When input is [57, 1, 76] the target is: 62\n",
      "When input is [57, 1, 76, 62] the target is: 73\n",
      "When input is [57, 1, 76, 62, 73] the target is: 61\n",
      "When input is [57, 1, 76, 62, 73, 61] the target is: 1\n",
      "When input is [57, 1, 76, 62, 73, 61, 1] the target is: 72\n",
      "When input is [57, 1, 76, 62, 73, 61, 1, 72] the target is: 74\n",
      "When input is [58] the target is: 72\n",
      "When input is [58, 72] the target is: 69\n",
      "When input is [58, 72, 69] the target is: 58\n",
      "When input is [58, 72, 69, 58] the target is: 71\n",
      "When input is [58, 72, 69, 58, 71] the target is: 54\n",
      "When input is [58, 72, 69, 58, 71, 54] the target is: 73\n",
      "When input is [58, 72, 69, 58, 71, 54, 73] the target is: 58\n",
      "When input is [58, 72, 69, 58, 71, 54, 73, 58] the target is: 65\n"
     ]
    }
   ],
   "source": [
    "# manual seed for random generator for this code if you would like to reproduce results\n",
    "#torch.manual_seed(1337)\n",
    "batch_size = 4 # how many chunks we will process at once\n",
    "chunk_size = 8 # max context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    #generating a small batch of data of inputs x and targets y\n",
    "    data = train_data if split== 'train' else val_data\n",
    "    ix = torch.randint(len(data) - chunk_size, (batch_size,)) # x position for random batch\n",
    "    x = torch.stack([data[i:i+chunk_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+chunk_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "x_batch, y_batch = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x_batch.shape)\n",
    "print(x_batch)\n",
    "print('targets:')\n",
    "print(y_batch.shape)\n",
    "print(y_batch)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for c in range(chunk_size): # chunk dimension\n",
    "        context = x_batch[b, :c+1]\n",
    "        target = y_batch[b,c]\n",
    "        print(f\"When input is {context.tolist()} the target is: {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Network\n",
    "\n",
    "Now that the data is prepared into train/validatin sets and batching, randomized positioning has been defined, and we have encoded those batches. I will now implement a neural network with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[69, 54, 73, 62, 58, 67, 73,  1],\n",
      "        [72, 72,  1, 68, 59,  1, 78, 68],\n",
      "        [ 1, 61, 58,  1, 73, 68, 68, 64],\n",
      "        [ 9,  1, 73, 61, 68, 74, 60, 61]])\n"
     ]
    }
   ],
   "source": [
    "print(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
